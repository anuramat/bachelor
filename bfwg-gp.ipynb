{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EEy0ioPVVo0"
   },
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "executionInfo": {
     "elapsed": 1255,
     "status": "ok",
     "timestamp": 1617469940425,
     "user": {
      "displayName": "Xhdhdh Cidjej",
      "photoUrl": "",
      "userId": "04686642470648718966"
     },
     "user_tz": -180
    },
    "id": "LoMpnMT6lyWW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'C:\\\\Users\\\\Arsen\\\\dev\\\\bachelor\\\\utils.py'>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "clear = lambda: clear_output(wait=True)\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import torchvision.transforms\n",
    "import utils\n",
    "\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "# !tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RchZGvjzViFx"
   },
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "executionInfo": {
     "elapsed": 5055,
     "status": "ok",
     "timestamp": 1617469944273,
     "user": {
      "displayName": "Xhdhdh Cidjej",
      "photoUrl": "",
      "userId": "04686642470648718966"
     },
     "user_tz": -180
    },
    "id": "Vx3om4aja2I0",
    "outputId": "92841465-5f9f-4fea-9ff5-e2a5a3d9fe5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of points in the dataset: 4205032\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stepNumber</th>\n",
       "      <th>particleFlag</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>dXdZ</th>\n",
       "      <th>dYdZ</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127141</td>\n",
       "      <td>2</td>\n",
       "      <td>0.982458</td>\n",
       "      <td>-0.269195</td>\n",
       "      <td>1130.724</td>\n",
       "      <td>-0.909843</td>\n",
       "      <td>-0.618070</td>\n",
       "      <td>99.899742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127141</td>\n",
       "      <td>2</td>\n",
       "      <td>8.087560</td>\n",
       "      <td>6.260150</td>\n",
       "      <td>1130.724</td>\n",
       "      <td>0.228221</td>\n",
       "      <td>-1.226108</td>\n",
       "      <td>105.682022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127141</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.482854</td>\n",
       "      <td>6.407821</td>\n",
       "      <td>1130.724</td>\n",
       "      <td>0.396534</td>\n",
       "      <td>-0.908100</td>\n",
       "      <td>106.127846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stepNumber  particleFlag         X         Y         Z      dXdZ      dYdZ  \\\n",
       "0      127141             2  0.982458 -0.269195  1130.724 -0.909843 -0.618070   \n",
       "1      127141             2  8.087560  6.260150  1130.724  0.228221 -1.226108   \n",
       "2      127141             2 -0.482854  6.407821  1130.724  0.396534 -0.908100   \n",
       "\n",
       "            P  \n",
       "0   99.899742  \n",
       "1  105.682022  \n",
       "2  106.127846  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.read_csv('beamfile.txt', sep=':')\n",
    "print('Total number of points in the dataset:', full_df.size)\n",
    "full_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "executionInfo": {
     "elapsed": 5047,
     "status": "ok",
     "timestamp": 1617469944273,
     "user": {
      "displayName": "Xhdhdh Cidjej",
      "photoUrl": "",
      "userId": "04686642470648718966"
     },
     "user_tz": -180
    },
    "id": "j67aUMUya5L2",
    "outputId": "b9f53655-c601-44e2-a92b-49de31743cee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting number of points: 1984365\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>dXdZ</th>\n",
       "      <th>dYdZ</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.982458</td>\n",
       "      <td>-0.269195</td>\n",
       "      <td>-0.909843</td>\n",
       "      <td>-0.618070</td>\n",
       "      <td>99.899742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.087560</td>\n",
       "      <td>6.260150</td>\n",
       "      <td>0.228221</td>\n",
       "      <td>-1.226108</td>\n",
       "      <td>105.682022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.482854</td>\n",
       "      <td>6.407821</td>\n",
       "      <td>0.396534</td>\n",
       "      <td>-0.908100</td>\n",
       "      <td>106.127846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y      dXdZ      dYdZ           P\n",
       "0  0.982458 -0.269195 -0.909843 -0.618070   99.899742\n",
       "1  8.087560  6.260150  0.228221 -1.226108  105.682022\n",
       "2 -0.482854  6.407821  0.396534 -0.908100  106.127846"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag = 'core' # core/halo/all\n",
    "\n",
    "if flag == 'core':\n",
    "    df = full_df[full_df['particleFlag']==2].drop(columns = ['stepNumber', 'particleFlag', 'Z'])\n",
    "elif flag == 'halo':\n",
    "    df = full_df[full_df['particleFlag']==3].drop(columns = ['stepNumber', 'particleFlag', 'Z'])\n",
    "elif flag == 'all':\n",
    "    df = full_df.drop(columns = ['stepNumber', 'particleFlag', 'Z'])\n",
    "else:\n",
    "    raise Exception('Choose the flag')\n",
    "    \n",
    "print('Resulting number of points:', df.size)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "executionInfo": {
     "elapsed": 5041,
     "status": "ok",
     "timestamp": 1617469944274,
     "user": {
      "displayName": "Xhdhdh Cidjej",
      "photoUrl": "",
      "userId": "04686642470648718966"
     },
     "user_tz": -180
    },
    "id": "t4legbhHTXbw"
   },
   "outputs": [],
   "source": [
    "real_data_raw = df.to_numpy()\n",
    "scaler = preprocessing.StandardScaler().fit(real_data_raw)\n",
    "real_data = scaler.transform(real_data_raw)\n",
    "dataset = torch.utils.data.TensorDataset(torch.FloatTensor(real_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSyqIh6tVX0L"
   },
   "source": [
    "# Define architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 5 # number of variables in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "executionInfo": {
     "elapsed": 1247,
     "status": "ok",
     "timestamp": 1617469940426,
     "user": {
      "displayName": "Xhdhdh Cidjej",
      "photoUrl": "",
      "userId": "04686642470648718966"
     },
     "user_tz": -180
    },
    "id": "Bmb3L6E2RKj3"
   },
   "outputs": [],
   "source": [
    "class SequentialLinearModule(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, layer_sizes, activation, out_activation, bias=True):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        # layers is the list that contains the sizes of linear layers between input and output\n",
    "        # [a, b, c]\n",
    "        layer_sizes.insert(0, in_dim)\n",
    "        layer_sizes.append(out_dim)\n",
    "        num_layers = len(layer_sizes)-1\n",
    "        \n",
    "        layers = [] # list of the modules that we put into sequential\n",
    "        for i in range(num_layers):\n",
    "            if i!=0:\n",
    "                layers.append(activation()) # activation after the last linear\n",
    "                layers.append(nn.BatchNorm1d(layer_sizes[i])) # batchnorm\n",
    "            layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1], bias=bias)) # linear\n",
    "            \n",
    "            \n",
    "        layers.append(out_activation()) # final activation\n",
    "        self.f = nn.Sequential(*layers) # combine everything\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "executionInfo": {
     "elapsed": 1242,
     "status": "ok",
     "timestamp": 1617469940427,
     "user": {
      "displayName": "Xhdhdh Cidjej",
      "photoUrl": "",
      "userId": "04686642470648718966"
     },
     "user_tz": -180
    },
    "id": "S8F6WLaZFKXu"
   },
   "outputs": [],
   "source": [
    "class Generator(SequentialLinearModule):\n",
    "    def __init__(self, noise_dim, n_dim, layer_sizes):\n",
    "        super().__init__(noise_dim, n_dim, layer_sizes, nn.ReLU, nn.Identity, True)\n",
    "        self.noise_dim = noise_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "executionInfo": {
     "elapsed": 1238,
     "status": "ok",
     "timestamp": 1617469940428,
     "user": {
      "displayName": "Xhdhdh Cidjej",
      "photoUrl": "",
      "userId": "04686642470648718966"
     },
     "user_tz": -180
    },
    "id": "S86adVJdJHDQ"
   },
   "outputs": [],
   "source": [
    "class Critic(SequentialLinearModule):\n",
    "    def __init__(self, n_dim, layer_sizes):\n",
    "        super().__init__(n_dim, 1, layer_sizes, nn.LeakyReLU, nn.LeakyReLU, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQIY8q9iVc3s"
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1231,
     "status": "ok",
     "timestamp": 1617469940428,
     "user": {
      "displayName": "Xhdhdh Cidjej",
      "photoUrl": "",
      "userId": "04686642470648718966"
     },
     "user_tz": -180
    },
    "id": "aTDvLLuyy8j9",
    "outputId": "839426fe-17a0-4135-8bc8-7b78fb28775c"
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "noise_dim = 128\n",
    "batch_size = 512\n",
    "batch_progress_period = int( len(dataset)/batch_size * 0.1 )\n",
    "num_epochs = 50\n",
    "lr_critic = lr\n",
    "lr_gen = lr/4\n",
    "critic_iterations = 5\n",
    "lambda_gp = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-X1vybfVgCD"
   },
   "source": [
    "# Initialize main objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "executionInfo": {
     "elapsed": 4699,
     "status": "ok",
     "timestamp": 1617469943902,
     "user": {
      "displayName": "Xhdhdh Cidjej",
      "photoUrl": "",
      "userId": "04686642470648718966"
     },
     "user_tz": -180
    },
    "id": "g9sV_O8KqRy3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "critic = Critic(n_dim, [32 for _ in range(2)]).to(device)\n",
    "gen = Generator(noise_dim, n_dim, [32 for _ in range(3)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critic(\n",
      "  (f): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=32, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Linear(in_features=32, out_features=1, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generator(\n",
      "  (f): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): Linear(in_features=32, out_features=5, bias=True)\n",
      "    (10): Identity()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(critic)\n",
    "print('\\n'*3)\n",
    "print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4695,
     "status": "ok",
     "timestamp": 1617469943905,
     "user": {
      "displayName": "Xhdhdh Cidjej",
      "photoUrl": "",
      "userId": "04686642470648718966"
     },
     "user_tz": -180
    },
    "id": "kefT5YWIRrJf",
    "outputId": "30e960be-1490-4c9e-8cfc-8b55577caaba"
   },
   "outputs": [],
   "source": [
    "opt_critic = optim.Adam(critic.parameters(), lr=lr_critic, betas=(0.0, 0.9))\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr_gen, betas=(0.0, 0.9))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGdWnsrQVkqU"
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "executionInfo": {
     "elapsed": 563,
     "status": "error",
     "timestamp": 1617471271792,
     "user": {
      "displayName": "Xhdhdh Cidjej",
      "photoUrl": "",
      "userId": "04686642470648718966"
     },
     "user_tz": -180
    },
    "id": "OYorpkoSPPpW",
    "outputId": "ccefabf6-c540-446a-d3b1-16f38993ce18"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    writer = SummaryWriter(f'runs/bfwg-gp_{datetime.datetime.now().strftime(\"%d.%m.%Y_%H.%M.%S\")}')\n",
    "    \n",
    "    running_critic_loss = 0\n",
    "    running_gen_loss = 0\n",
    "    \n",
    "    last_time = None\n",
    "    eta = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # batch is stored in \"real\" variable (as opposed to \"fake\" generated data)\n",
    "        for batch_idx, (real, ) in enumerate(dataloader):\n",
    "\n",
    "            real = real.to(device)\n",
    "\n",
    "            for _ in range(critic_iterations):\n",
    "\n",
    "                # generate fake data\n",
    "                noise = torch.randn(real.shape[0], noise_dim).to(device) # noise for generator\n",
    "                fake = gen(noise) # fake data\n",
    "\n",
    "                # critic training\n",
    "                real_preds = critic(real)\n",
    "                fake_preds = critic(fake)\n",
    "                gp = utils.gradient_penalty(critic, real, fake, device)\n",
    "                loss_critic = torch.mean(fake_preds) - torch.mean(real_preds) + lambda_gp*gp\n",
    "                critic.zero_grad()\n",
    "                # without retain_graph all graph variables will be freed to optimize for memory\n",
    "                loss_critic.backward(retain_graph=True)\n",
    "                opt_critic.step()\n",
    "                running_critic_loss += loss_critic.detach().cpu().numpy()\n",
    "\n",
    "            # generator training\n",
    "            fake_preds = critic(fake)\n",
    "            loss_gen = -torch.mean(fake_preds)\n",
    "            gen.zero_grad()\n",
    "            loss_gen.backward()\n",
    "            opt_gen.step()\n",
    "            running_gen_loss += loss_gen.detach().cpu().numpy()\n",
    "            \n",
    "            if (batch_progress_period!=0 and batch_idx % batch_progress_period == 0) or batch_idx==0:\n",
    "                \n",
    "                current_step = epoch*len(dataloader) + batch_idx\n",
    "                \n",
    "                text = ''\n",
    "                \n",
    "                # epoch num and %\n",
    "                text += f'Epoch {epoch+1}/{num_epochs}\\n'\n",
    "                text += f'{100*epoch/num_epochs:.2f}%\\n\\n'\n",
    "                # batch num and %\n",
    "                text += f'Batch {batch_idx+1}/{len(dataloader)}\\n'\n",
    "                text += f'{100*batch_idx/len(dataloader):.2f}%\\n\\n'\n",
    "                # eta\n",
    "                if last_time and batch_progress_period!=0:\n",
    "                    epochs_rem = num_epochs-epoch-1\n",
    "                    batches_rem = epochs_rem*len(dataloader) + (len(dataloader) - batch_idx)\n",
    "                    eta = int(batches_rem * (time.time() - last_time)/batch_progress_period)\n",
    "                    text += f'ETA {datetime.timedelta(seconds=int(eta))}\\n\\n'                   \n",
    "                else:\n",
    "                    text += 'ETA N/A\\n\\n'\n",
    "                last_time = time.time()\n",
    "                writer.add_text('progress', text, current_step)\n",
    "                \n",
    "                \n",
    "                # histograms\n",
    "                img_buf = utils.draw_hist(real_data, gen, device, df)\n",
    "                img = Image.open(img_buf)\n",
    "                img = torchvision.transforms.ToTensor()(img)\n",
    "                writer.add_image('histograms', img, current_step)\n",
    "                \n",
    "                \n",
    "                # memory usage\n",
    "                writer.add_scalar('memory', torch.cuda.max_memory_allocated()/1024**3, current_step)\n",
    "                torch.cuda.reset_peak_memory_stats()\n",
    "                \n",
    "                \n",
    "                # loss plots\n",
    "                running_critic_loss /= batch_progress_period*critic_iterations\n",
    "                running_gen_loss /= batch_progress_period\n",
    "                writer.add_scalar('loss/critic', running_critic_loss, current_step)\n",
    "                writer.add_scalar('loss/generator', running_gen_loss, current_step)\n",
    "                running_critic_loss = 0\n",
    "                running_gen_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNBaRV3NAD7Z6IdingWfkOz",
   "collapsed_sections": [],
   "mount_file_id": "1a7rDIvb294KRdEVYVXYfqYJMa1YeQjAR",
   "name": "big_fysics_gan.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
